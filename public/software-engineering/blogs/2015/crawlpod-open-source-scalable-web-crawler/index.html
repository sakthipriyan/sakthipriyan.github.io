<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Crawlpod - open source scalable web crawler | Sakthi Priyan H</title>
    <meta name="description" content="Building Software. Building Wealth.">

    
    <link rel="stylesheet" href="https://sakthipriyan.com/css/style.css">


    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/default.min.css">
    

    
</head>





<body class="software-engineering">
    <header class="site-header">
    <nav class="main-nav">
        
            
            
            
            
            
            <div class="logo">
                <a href="https://sakthipriyan.com/" class="name-link">Sakthi Priyan H</a>
                <span class="separator"> | </span>
                
                <a href="/software-engineering/" class="name-link">Software Engineering</a>
            </div>
            <ul class="nav-links">
                
                
                
                
                
                    
                    
                    
                        
                            
                            
                                <li><a href="https://sakthipriyan.com/software-engineering/blogs/">Blogs</a></li>
                            
                        
                    
                
                    
                    
                    
                
                    
                    
                    
                
                    
                    
                    
                        
                            
                            
                            
                                
                                    
                                
                            
                            
                                <li><a href="https://sakthipriyan.com/software-engineering/tags/">Tags</a></li>
                            
                        
                    
                
                    
                    
                    
                        
                            
                            
                        
                    
                
                    
                    
                    
                        
                            
                            
                        
                    
                
            </ul>
        
    </nav>
</header>

    
<nav class="breadcrumb" aria-label="breadcrumb">
    <ol class="breadcrumb-list">
        <li class="breadcrumb-item">
            <a href="https://sakthipriyan.com/">Home</a>
        </li>
            
            
                
                
                
                
                
                
                
                
                <li class="breadcrumb-item">
                    
                        <a href="/software-engineering/">Software Engineering</a>
                    
                </li>
                
                
                
                
                
                    
                    
                        
                        
                        <li class="breadcrumb-item">
                            
                                <a href="/software-engineering/blogs/">Blogs</a>
                            
                        </li>
                        
                    
                
            
            
            
            
            <li class="breadcrumb-item active" aria-current="page">
                <span>Crawlpod - open source scalable web crawler</span>
            </li>
            
        </ol>
</nav>


    <main>
        
<article class="blog-post">
    <header class="post-header">
        <div class="post-header-grid">
            <div class="title-column">
                <h1 class="post-title">
                    Crawlpod - open source scalable web crawler
                    
                    <div class="post-subtitle">built on top of Scala and Akka framework.</div>
                    
                </h1>
            </div>
            
            <div class="date-column">
                <i class="calendar-icon">📅</i>
                <time datetime="2015-12-12">
                    Dec 12, 2015
                </time>
            </div>
            
        </div>
    </header>

    <div class="post-content">
        <h3 id="intro">Intro</h3>
<p>Earlier I wrote about <a href="/2015/04/18/building-a-distributed-web-crawler.html">Building a scalable distributed web crawler</a>.
Recently I built an open source one based on it.</p>
<h3 id="code">Code</h3>
<p>Interested in reading code rather than this blog post. <a href="https://github.com/sakthipriyan/crawlpod">Here</a> it is for you.</p>
<h3 id="new-goals">New Goals</h3>
<ul>
<li>Self contained, should be able to run in a single node.</li>
<li>Fully asynchronous, no blocking call anywhere.</li>
<li>Easy to plug in different providers for underlying storage, say cache, queue, etc.,</li>
</ul>
<h3 id="tech-stack">Tech Stack</h3>
<ul>
<li>Entire framework is written in <a href="http://www.scala-lang.org/">Scala</a>. Apparently, now Scala is my default JVM language.</li>
<li>Everything is a <a href="http://akka.io/">Akka</a> actor and so clear separation of responsibilities.</li>
<li><a href="http://mongodb.org">Mongodb</a> used for various sub systems and mongodb <a href="http://mongodb.github.io/mongo-scala-driver">scala driver</a> is used.</li>
<li><a href="http://dispatch.databinder.net/Dispatch.html">Dispatch</a> for http requests and <a href="http://jsoup.org/">jsoup</a> as dom parser.</li>
<li><a href="http://www.scalatest.org/">Scalatest</a> for testing and <a href="http://logback.qos.ch/">Logback</a> for logging.</li>
<li><a href="http://json4s.org/">Json4s</a> for handling JSON and <a href="https://github.com/scala/scala-xml">Scala xml</a> for XML.</li>
</ul>
<h3 id="design">Design</h3>
<p>Let me explain the design in terms of Storage systems and Actors involved.</p>
<h4 id="storage-systems">Storage systems</h4>
<p>Following four storage systems are required. They can be implemented on top various providers based on the use case and scale. Currently all four are implemented using Mongodb.</p>
<ul>
<li><strong>Queue</strong> is used to queue http requests.</li>
<li><strong>Request Store</strong> is used to determine if a given request is already processed or not.</li>
<li><strong>Raw Store</strong> is used to cache the entire response from the http request.</li>
<li><strong>Json Store</strong> is used to store the extracted JSON from the response.</li>
</ul>
<p>In its earlier avatar, Kafka was used for Queue, Couchbase was used for Request Store and Json Store and S3 was used for Raw Store.</p>
<h4 id="actors-involved">Actors involved</h4>
<p>Now comes the interesting part, Actors.</p>
<blockquote>
<p>All the world&rsquo;s a stage, and all the men and women merely players.<br>
- <strong>William Shakespeare</strong>,  <em><a href="http://shakespeare.mit.edu/asyoulikeit/full.html">As You Like It</a></em>.</p>
</blockquote>
<p>We have following actors with specific responsibility.</p>
<ul>
<li><strong>Controller Actor</strong> is the lead actor which controls the flow and not yet mature.</li>
<li><strong>Http Actor</strong> is a brave actor which sends HTTP request. Once HTTP response is received, it sends it to <em>Extract Actor</em> and <em>Raw Store Actor</em>.</li>
<li><strong>Extract Actor</strong> is a soft hardworking actor, which gets HTTP response and process it. It sends extracted new requests to <em>Queue Actor</em> and extracted json to <em>Json Store Actor</em>. Once job done, it reports to <em>Controller Actor</em> and also tell <em>Request Store Actor</em> that particular request is processed.</li>
<li><strong>Queue Actor</strong> is the friend of <em>Controller Actor</em> which is responsible for enqueue and  dequeue of HTTP requests to the queue. When dequeued it sends the request to <em>Request Store Actor</em> to see if it has to be processed.</li>
<li><strong>Raw Store Actor</strong> is the local cache actor which caches HTTP response. If it doesn&rsquo;t have response for specific request, it sends that to its brave friend <em>Http Actor</em>. In case, it already has the response, it send that to hardworking <em>Extract Actor</em>.</li>
<li><strong>Json Store Actor</strong> is an easy actor, which just writes down all extracted JSON. It is the most underrated actor in the play which does its job very well.</li>
<li><strong>Request Store Actor</strong> is the tough one in this lot, which do the heavy lifting of tracking all requests and also, implements mechanism to re extract the data.</li>
</ul>
<p>Better read the code,  <a href="https://github.com/sakthipriyan/crawlpod/blob/master/src/main/scala/net/crawlpod/core/CoreActors.scala"><code>CoreActors.scala</code></a>. Also look at,  <a href="https://github.com/sakthipriyan/crawlpod/blob/master/src/main/scala/net/crawlpod/core/ControllerActor.scala"><code>ControllerActor.scala</code></a> which is not yet mature.</p>
<h4 id="http">Http</h4>
<p>Currently <code>dispatch</code> is used as http client. May be moving to akka http later.
Http client is used in the <em>Http Actor</em></p>
<h4 id="core-models">Core models</h4>
<p>Look at the <a href="https://github.com/sakthipriyan/crawlpod/blob/master/src/main/scala/net/crawlpod/core/Models.scala"><code>Models</code></a> file.
Important two classes are explained here.</p>
<ol>
<li>
<p><strong>CrawlRequest</strong> - Contains all data required to send HTTP request.</p>
<pre><code> case class CrawlRequest (
     url: String, // URL of request, with query params.
     extractor: String, // package.classname.methodname of extractor.
     method: String = &quot;GET&quot;, // Http method.
     headers: Option[Map[String, String]] = None, // Optional Header.
     // Optional data that can be passed around.
     passData: Option[Map[String, String]] = None,
     requestBody: Option[String] = None, //Post request body
     cache: Boolean = true )
</code></pre>
</li>
<li>
<p><strong>CrawlResponse</strong> - represents the http response with additional data.</p>
<pre><code> case class CrawlResponse(
     request: CrawlRequest, // Original crawl request object
     status: Int, // http status. Say 200, 404, etc.,
     headers: Map[String, List[String]], // Response headers
     body: String, // response body
     created: Long = System.currentTimeMillis,
     timeTaken: Int = -1) // Time taken to get this response.
</code></pre>
</li>
</ol>
<h3 id="now-lets-crawl">Now lets Crawl.</h3>
<p>Following is an illustrative one, it won&rsquo;t work as such.<br>
Assumed that mongodb is running somewhere and configured <code>mongodb.url</code> in <code>application.conf</code></p>
<h4 id="steps-1-2-3">Steps 1, 2, 3.</h4>
<ol>
<li>
<p>Create a extractor code which returns <code>Extract</code> object.</p>
<pre><code> package net.crawlpod.extract

 class Example {
   def init(response: CrawlResponse): Extract = {
     val dom = response.toDom
     // Heavy lifting next two lines,
     // Custom implementation for various pages of interest.
     val docs = extractDocsFromDom(dom) // Extract json docs.
     val requests = extractRequestsFromDom(dom) // Extract next set of urls.
     new Extract(docs,requests)
   }
 }
</code></pre>
</li>
<li>
<p>Add an entry to the queue. Since Mongodb is used, we have to add an Json object into <code>queue</code> collection.</p>
<pre><code> {
     &quot;url&quot; : &quot;http://example.com&quot;,
     &quot;extractor&quot; : &quot;net.crawlpod.extract.Example.init&quot;,
     &quot;method&quot; : &quot;GET&quot;,
     &quot;passData&quot; : {
         &quot;date1&quot; : &quot;01-Apr-2014&quot;,
         &quot;date2&quot; : &quot;31-Mar-2015&quot;
     },
     &quot;cache&quot; : true,
     &quot;used&quot; : false
 }
</code></pre>
</li>
<li>
<p>Now run the application by launching <code>net.crawlpod.core.CrawlPod</code></p>
</li>
</ol>
<h4 id="output">Output</h4>
<ul>
<li>We can more find more data added to following collections in Mongodb.
<ul>
<li>queue</li>
<li>request</li>
<li>raw</li>
<li>json</li>
</ul>
</li>
<li>Just export the data from json collection. We are done!</li>
</ul>
<h3 id="just-into-second-gear">Just into second gear.</h3>
<ul>
<li>I hope this is just a start, not yet ready for general use.</li>
<li>Lot of ideas yet to be implemented to make it easier to use.</li>
<li>Need to document <code>Crawlpod</code> in its own <a href="http://crawlpod.net">site</a> as it grows.</li>
</ul>
<p>Kudos! you read till this point, just go ahead and share it. Thanks!</p>

    </div>

    
    
    
        
        
    
    
    
    <div class="post-tags-footer">
        <span class="tags-label">🏷️ Tags:</span>
        
        <a href="/software-engineering/tags/crawlpod" class="tag">crawlpod</a>
        
        <a href="/software-engineering/tags/web-crawler" class="tag">web-crawler</a>
        
        <a href="/software-engineering/tags/scala" class="tag">scala</a>
        
        <a href="/software-engineering/tags/akka" class="tag">akka</a>
        
        <a href="/software-engineering/tags/mongodb" class="tag">mongodb</a>
        
        <a href="/software-engineering/tags/design" class="tag">design</a>
        
        <a href="/software-engineering/tags/open-source" class="tag">open-source</a>
        
    </div>
    
</article>
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'sakthipriyan';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

    </main>

    <footer class="site-footer">
    <p>&copy; 2025 Sakthi Priyan H. Built with Hugo and Continuum theme.</p>
</footer>

    

        
        
        <script>
            function runHighlightJS() {
                if (window.hljs) { hljs.highlightAll(); }
            }
        </script>
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.11.1/build/highlight.min.js" onload="runHighlightJS()"></script>
        

    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5NGEJ767SK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-5NGEJ767SK');
    </script>
</body>

</html>